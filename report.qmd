---
title: "IML term project 2025"
format: typst
execute:
    echo: false
jupyter: python3
---

**Team:** Overfit & Chill (Group 52)  
**Members:**  
Christos Zonias  
Kokoro Horiuchi  
Mikhail Golubkov  

**Date:** December 7, 2025

{{< pagebreak >}}

# Preliminary Report

## 1. Introduction
This project focuses on the classification of atmospheric new particle formation (NPF) events using environmental sensor data collected at the Hyytiälä forestry field station (SMEAR II mast). NPF refers to the process by which small molecular clusters form into larger aerosol particles, influencing cloud formation, weather patterns, and air quality. Understanding the conditions under which NPF occurs is of significant scientific and environmental importance, particularly for assessing air pollution dynamics and climate interactions.

The dataset contains daily aggregated meteorological and aerosol measurements, including temperature, humidity, and condensation sink, recorded at multiple heights. Each day is labeled with an event type: nonevent (no NPF) or one of three NPF event classes (Ia, Ib, II). The primary task is to develop a binary classifier to distinguish between event (any NPF type) and nonevent days. The secondary task involves multi-class classification across the four event categories.

From a machine learning perspective, this represents a supervised classification problem with structured, clean data. The objective is not to achieve state-of-the-art predictive performance, but to systematically apply and evaluate data preprocessing, feature selection, model training, and validation techniques. The project emphasizes methodological rigor, interpretability, and reasoned decision-making over pure accuracy, providing a practical exercise in building, analyzing, and reporting on a real-world classification pipeline.

## 2. Work Completed to Date
### 2.1 Data Acquisition and Initial Setup

**Libraries Used:**

* pandas for data manipulation  
* numpy for numerical operations  
* matplotlib.pyplot for core plotting library  

**Column Structure:**

* Each sensor measurement appears as pairs of .mean and .std columns.
* Sensors include: CO2168, CO2336, CO242, CO2504, Glob, T672, T84, UV_A, UV_B, CS, and others.
* Additional columns: id, class4, date, partlybad.

**Removed Columns (Data Handling):**

* date
* partlybad  

**Feature Analysis:**

* Identified 10 features with minimal variance (top 4 are CS.std, CS.mean, PTG.std, PTG.mean)
* Variance range: 4.6e-07 (CS.std) to 2.1e-02 (SO2168.std)
* Created heatmap visualization  

![Heatmap](featurecorrelationheatmap.png)

* To identify which features are most promising for distinguishing between the 4 classes of environmental events/conditions:  

![EDA](EDAfeatures.png)

* Scatterplots of key feature pairs reveal that NPF events (Ia, Ib, II) primarily occur under high radiation and low humidity conditions. Nonevent days cluster in regions of low PAR.mean/Glob.mean and high RHIRGA336.mean. Temperature provides secondary separation, with nonevents frequently occurring on cold, humid days and events on warmer, sunnier days. The three event classes partly overlap, indicating that subclassification (Ia, Ib, II) is inherently more difficult than the binary event/nonevent classification.  

![Scatterplot](scatterplot.png)

### 2.2 Basic Ideas and Solution Approach
#### Proposed Solution Strategy #1: Stacking Ensemble Classification
The proposed solution implements a Stacking Ensemble machine learning pipeline designed to maximize predictive accuracy while minimizing the risk of overfitting. Rather than relying on a single algorithm, the strategy leverages the strengths of three distinct "expert" models and utilizes a meta-learner to optimize their collective output. The pipeline is robust to noise, handles temporal seasonality through cyclical encoding, and employs rigorous feature selection to ensure computational efficiency.

Data preprocessing:

* Preserve the cyclical continuity of time to capture seasonal patterns more effectively.
* Missing values are replaced with the median of their respective columns. The median is chosen over the mean because it is robust to outliers, preventing extreme values from skewing the underlying data distribution.
* Features are scaled to have a mean of 0 and a standard deviation of 1 (standardization).
* A preliminary Random Forest is trained to evaluate feature importance, and any irrelevant or noisy features are removed.

Base learners:

* HistGradientBoostingClassifier (Boosting) for bias reduction.
* RandomForestClassifier (Bagging) for variance reduction.
* ExtraTreesClassifier (Randomized Bagging) for decorrelation and restrain overfitting. 

Meta-learner:
The predictions generated by the three complex base models serve as inputs to the meta-learner. Since these inputs are already highly processed probability landscapes, a simple, linear model is ideal for the final aggregation, so Logistic Regression is used.

{{< pagebreak >}}

## 3. Data Analysis Stages

### 3.1 Initial Data Exploration
```{python}
print(np.shape(df))
print(np.shape(df_test))
df.describe()

df = df.drop(["date", "partlybad"], axis=1)
df.head()
